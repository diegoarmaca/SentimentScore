{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving movie rating prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: How can we improve the movie rating prediction?\n",
    "In the exploration part of the assignment, we intend to find ways to improve the rating prediction model. On the way of sharpening the prediction, we also prepared the dataset to subsets of test set and training set. We then use the test set to test to model trained by the training set. After that, we sharpened the model to better predict the movie rating. Therefore, the test is done twiceâ€”one for the original prediction, and another for the sharpened prediction. We then have the test results of the two for comparison. CSV files and the visualization of the findings will also be presented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing necessary libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used of a list of libraries that allows us to perform actions without spending extensive of time to write our own code. _pandas_ is used for loading and reading CSV tables, and matplotlib is used to visualize our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TextIO, List, Union, Dict, Tuple\n",
    "import doctest\n",
    "from sentiment import *\n",
    "from random import shuffle\n",
    "import csv\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Partitioning data into Test and training data\n",
    "We split the given dataset into two subsets for testing and training with the ratio of 20 : 80. The ratio is custimizable by changing the test_size variable of partition_dataset function. The dataset is shuffled before the splitting to ensure the randomness of each sample. However, the ratio of the movie rating scores is kept representative of the population dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_dataset(file:TextIO, file_name:str, test_size:float) -> Dict:\n",
    "    \"\"\"Precondition: test_size > 0.0 and < 1.0 (one decimal)\n",
    "    Create two datasets sorted randomly from the original. The test_dataset has the size\n",
    "    requested in test_size, and the trainin_dataset has the remaining size.\n",
    "    Print a message e.g., \"The files: test_data.txt and training_data.txt were created\",\n",
    "    and return a dictionary e.g., {'test': 'test_data.txt', 'training': 'training_data.txt'}\n",
    "    \n",
    "    >>> file_names = partition_dataset(open('full.txt', 'r'), 'data', 0.2)\n",
    "    The files: test_data.txt and training_data.txt were created\n",
    "    >>> file_names\n",
    "    {'test': 'test_data.txt', 'training': 'training_data.txt'}\n",
    "    \"\"\"\n",
    "    all_reviews = file.readlines()\n",
    "    shuffle(all_reviews)\n",
    "    rating_counts = {}\n",
    "    test_set = []\n",
    "    training_set = []\n",
    "    for review in all_reviews:\n",
    "        if review[0] in rating_counts:\n",
    "            rating_counts[review[0]].append(review)\n",
    "        else:\n",
    "            rating_counts[review[0]] = [review]\n",
    "    for rating, reviews in rating_counts.items():\n",
    "        length_of_test_data = round(len(reviews) * (test_size))\n",
    "        test_set.extend(reviews[:length_of_test_data])\n",
    "        training_set.extend(reviews[length_of_test_data:])\n",
    "    test_file_name = \"test_\" + file_name + \".txt\"\n",
    "    training_file_name = \"training_\" + file_name + \".txt\"\n",
    "\n",
    "    with open(test_file_name, 'w') as test_file:\n",
    "        for row in test_set:\n",
    "            test_file.write(row)\n",
    "\n",
    "    with open(training_file_name, 'w') as training_file:\n",
    "        for row in training_set: \n",
    "            training_file.write(row)\n",
    "\n",
    "    print('The files: '+ test_file_name + ' and ' + training_file_name + ' were created')\n",
    "    return {'test':test_file_name, 'training':training_file_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sharpening the model\n",
    "In the many ways we have tried, we found that removing the given common words and neutral words improves the prediction model. We removed the common words from the kss dictionary because they may dilute the impact of more context specific words. [Why removing neutral words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen_model(common_words_file:TextIO ,kss: Dict[str, List[int]])->Dict:\n",
    "    \"\"\"Sharpen the prediction model by removing neutral words and common words from kss dictionary. \n",
    "    Return kss_sharpened as the sharpened kss dictionary.\n",
    "    \"\"\"\n",
    "    common_words_file = common_words_file.read().splitlines()\n",
    "    kss_sharpened = {}\n",
    "    for word, value in kss.items():\n",
    "        if (judge(value[0]/value[1]) != 'neutral') or (word not in common_words_file):\n",
    "            kss_sharpened[word] = value\n",
    "    return kss_sharpened    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get relevant numerical information\n",
    "The following four functions gets four values that will be used to compare the the original prediction model and the sharpen prediction model. \n",
    "\n",
    "Predicted Sentiment Score: A sentiment of a statement(review) determined by the model.\n",
    "\n",
    "Predicted Movie Rating: Because the PSS is ratio value and the movie rating is ordinal value, the predict_movie_rating will use the PSS score to predict a movie rating in ordinal value. \n",
    "\n",
    "\n",
    "The absolute difference: The absolute difference between PSS and the actual rating\n",
    "\n",
    "If PSS is close enough to the actual rating: is_close_eval is another way to tell us if a PSS is considered close to the actual rating. Here, we put the threshold as 0.05. The values of the actual score and the PSS are considered closed if the difference is smaller than 0.05.\n",
    "\n",
    "Then, report_errors will return a list of above four values for a review. Lastly, the report_mean_error function will return the mean error of all the errors between the actual scores and the predicted scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_movie_rating(pss_score: float)->int:\n",
    "    \"\"\" Get the Predicted Sentiment Score and use it to predict the movie rating from a review statement. \n",
    "    >>> predict_movie_rating(2.8)\n",
    "    3\n",
    "    >>> predict_movie_rating(1.2)\n",
    "    1\n",
    "    \"\"\"\n",
    "    return int(round(pss_score))\n",
    "\n",
    "def is_close_eval(pss_score, actual_rating)-> bool:\n",
    "    \"\"\" Get the difference between the actual movie rating and the Predicted Sentiment Score and determine\n",
    "    if the difference is larger than 0.05. If the difference is larger than 0.05, return False. \n",
    "    If the difference is smaller than or equals to 0.05, return True.\n",
    "    >>> is_close_eval(2.05, 2)\n",
    "    True\n",
    "    >>> is_close_eval(2.02, 2)\n",
    "    True\n",
    "    >>> is_close_eval(3.05, 2)\n",
    "    False\n",
    "    \"\"\"\n",
    "    return math.isclose(pss_score, actual_rating, abs_tol=0.05)\n",
    "\n",
    "def report_errors(review: str, kss: Dict[str, List[int]])->List:\n",
    "    \"\"\" Return a list of scores for each review in the follow order: \n",
    "    1. the Predicted Sentiment Score, \n",
    "    2. the predicted movie rating, \n",
    "    3. the absolute difference between PSS and the actual rating, \n",
    "    4. a boolean value returned by is_close_eval()\n",
    "    \"\"\"\n",
    "    actual_rating = float(review[0])\n",
    "    absolute_errors = []\n",
    "    pss_score = statement_pss(review, kss)\n",
    "    review_scores = []\n",
    "    if pss_score != None:\n",
    "        is_close_val = is_close_eval(pss_score, actual_rating)\n",
    "        absolute_error = round((abs(float(pss_score) - actual_rating)), 2)\n",
    "        absolute_errors.append(absolute_error)\n",
    "        review_scores = [pss_score, predict_movie_rating(pss_score), absolute_error, is_close_val]\n",
    "        return review_scores\n",
    "\n",
    "def report_mean_error(absolute_errors:List[float]):\n",
    "    \"\"\" Return the mean abosolute error of a given list of error values.\n",
    "    >>> [1.56, 0.24, 0.69]\n",
    "    0.83\n",
    "    \"\"\"\n",
    "    if len(absolute_errors) != 0:\n",
    "        mean_absolute_error = round(sum(absolute_errors)/len(absolute_errors), 5)\n",
    "        return mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare the models\n",
    "After retrieving the four values for each model by the previous step, we can now use them to compare the original model and the sharpened model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_pss_models(test_file:TextIO, common_words_file:TextIO ,kss: Dict[str, List[int]], name_datasets) -> Dict:\n",
    "    \"\"\"Create a csv dataset with the comparison of the scores given by the kss model and the original ones. \n",
    "    Print the message \"The file: reviews_comparison.csv was created\" and return a dictionary with the \n",
    "    Mean_Absolute_Error(MAE) and Mean_Absolute_Error(MAE)_Sharpened of the dataset e.g., \n",
    "    {'Mean_Absolute_Error(MAE)': 1.00225, 'Mean_Absolute_Error(MAE)_Sharpened': 0.96186}\n",
    "    >>> file1 = open('full.txt', 'r')\n",
    "    >>> file2 = open('most_common_english_words.txt', 'r')\n",
    "    >>> kss = extract_kss(file1)\n",
    "    >>> testing_result = compare_pss_models(file1, file2, kss, 'data')\n",
    "    The file: reviews_data.csv was created\n",
    "    >>> file1.close()\n",
    "    >>> file2.close()\n",
    "    \"\"\"\n",
    "    scores_comparison = []\n",
    "    original_report_list = []\n",
    "    sharpened_report_list = []\n",
    "    original_absolute_errors = []\n",
    "    sharpened_absolute_errors = []\n",
    "    test_reviews = test_file.readlines()\n",
    "    \n",
    "    ### Sharpend kss by removing all common words\n",
    "    kss_sharpened = sharpen_model(common_words_file ,kss)\n",
    "   \n",
    "    # Iterate over each review in order to get predicted rating and MAE for kss and the sharpened version of kss          \n",
    "    for review in test_reviews:\n",
    "        statement = review[1:].strip()\n",
    "        original_report = report_errors(review, kss)\n",
    "        sharpened_report = report_errors(review, kss_sharpened)\n",
    "        if statement_pss(review, kss) != None and statement_pss(review, kss_sharpened):\n",
    "            original_report_list.append(original_report)\n",
    "            sharpened_report_list.append(sharpened_report)\n",
    "            original_absolute_errors.append(original_report[2])\n",
    "            sharpened_absolute_errors.append(sharpened_report[2])\n",
    "            scores_comparison.append([statement, review[0], \n",
    "                                      round(original_report[0],2), original_report[1], original_report[2], original_report[3], \n",
    "                                      round(sharpened_report[0],2), sharpened_report[1],sharpened_report[2], sharpened_report[3]])\n",
    "            \n",
    "    # Get mean absolute errors from the original and the sharpened model        \n",
    "    mean_absolute_error = report_mean_error(original_absolute_errors)\n",
    "    mean_absolute_error_sharpened = report_mean_error(sharpened_absolute_errors)\n",
    "\n",
    "    # Save all reviews with their predicted scores and MAE using kss and kss_sharpened     \n",
    "    with open('reviews_'+ name_datasets + '.csv', mode ='w') as comparison_file:\n",
    "        comparison_writer = csv.writer(comparison_file, delimiter=\",\", quotechar='\"', quoting = csv.QUOTE_MINIMAL)\n",
    "        comparison_writer.writerow([\"Mean Absolute Error(MAE): \" + str(mean_absolute_error) ])\n",
    "        comparison_writer.writerow([\"Mean Absolute Error(MAE)   Sharpened: \" + str(mean_absolute_error_sharpened) ])\n",
    "        comparison_writer.writerow([\"-\",\"-\",\"-\",\"-\",\"-\"])\n",
    "        comparison_writer.writerow([\"Review\", \"Original Rating\", \n",
    "                                    \"PSS Score\", \"Predicted Rating\", \"Absolute Error\", \"Evaluation Result\", \n",
    "                                    \"PSS Score Sharpened\", \"Predicted Rating Sharpened\",\"Absolute Error Sharpened\", \"Evaluation Result Sharpened\"])\n",
    "        for row in scores_comparison:\n",
    "            comparison_writer.writerow(row)\n",
    "\n",
    "    print('The file: ' + 'reviews_'+ name_datasets + '.csv' + ' was created')\n",
    "    return {\"Mean_Absolute_Error(MAE)\": mean_absolute_error,\"Mean_Absolute_Error(MAE)_Sharpened\":mean_absolute_error_sharpened}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Open the files to execute the comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function runs the test for more than one dataset and returns the Mean Absolute Error for each dataset as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_test(datasets: Dict[str, str], partition_size):\n",
    "    \"\"\"Precondition: the dictionary should have the form {name_dataset:dataset} e.g., {\"small\":\"small.txt\",\"medium\":\"medium.txt\",\"full\":\"full.txt\"}  \n",
    "    Run compare_pss_models function for various datasets.\n",
    "    \"\"\"\n",
    "    for name in datasets:\n",
    "        with open(datasets[name], 'r') as file:\n",
    "            file_names = partition_dataset(file, name, partition_size)\n",
    "        with open(file_names['training'], 'r') as training_file:\n",
    "                kss = extract_kss(training_file)  \n",
    "        with open(file_names['test'], 'r') as test:\n",
    "            with open(most_common_words) as common_words_file:\n",
    "                testing_result = compare_pss_models(test, common_words_file, kss, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code allows to assess the functions created and the KSS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'small.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b3f315a25738>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmost_common_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"most_common_english_words.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mexecute_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mdoctest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-9c8467b4c02e>\u001b[0m in \u001b[0;36mexecute_test\u001b[0;34m(datasets, partition_size)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mfile_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartition_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'small.txt'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #Create a dictionary containing diferent datasets, in order to compare accuracies among each other.\n",
    "    datasets =  {\n",
    "        \"small\"     : \"small.txt\",\n",
    "        \"medium\"    : \"medium.txt\",\n",
    "        \"full\"      : \"full.txt\"\n",
    "    }        \n",
    "    \n",
    "    most_common_words = \"most_common_english_words.txt\"\n",
    "    execute_test(datasets, 0.1)\n",
    "    doctest.testmod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the analysis, we need to import our result datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'reviews_full.csv' does not exist: b'reviews_full.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7113f30b7667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluated_reviews_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reviews_full.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mevaluated_reviews_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'reviews_full.csv' does not exist: b'reviews_full.csv'"
     ]
    }
   ],
   "source": [
    "evaluated_reviews_full = pd.read_csv('reviews_full.csv', header=3)\n",
    "evaluated_reviews_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'reviews_medium.csv' does not exist: b'reviews_medium.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9740ea4c1aec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluated_reviews_medium\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reviews_medium.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mevaluated_reviews_medium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'reviews_medium.csv' does not exist: b'reviews_medium.csv'"
     ]
    }
   ],
   "source": [
    "evaluated_reviews_medium = pd.read_csv('reviews_medium.csv', header=3)\n",
    "evaluated_reviews_medium.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'reviews_small.csv' does not exist: b'reviews_small.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-364fb8ecdc75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluated_reviews_small\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reviews_small.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mevaluated_reviews_small\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'reviews_small.csv' does not exist: b'reviews_small.csv'"
     ]
    }
   ],
   "source": [
    "evaluated_reviews_small = pd.read_csv('reviews_small.csv', header=3)\n",
    "evaluated_reviews_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to plot a histogram which is a good tool to interpret the distribution of the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluated_reviews_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3e661d872680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Subplot 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m131\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moriginal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluated_reviews_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Original Rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'PSS'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Original Rating'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Scores Full'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluated_reviews_full' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Distributions for Full dataset\n",
    "plots_size = (14,3)\n",
    "plt.figure(1, figsize=plots_size)\n",
    "#Subplot 1\n",
    "original = plt.subplot(131)\n",
    "original.hist(evaluated_reviews_full['Original Rating'], bins=5, alpha=0.5, label='PSS')\n",
    "original.set_title('Original Rating')\n",
    "original.set_xlabel('Scores Full')\n",
    "original.set_ylabel('Reviews Full')\n",
    "#Subplot 2\n",
    "predicted = plt.subplot(132)\n",
    "predicted.hist(evaluated_reviews_full['PSS Score'], bins=5, alpha=0.5, label='PSS', color='#00A658')\n",
    "predicted.set_title('PSS Score')\n",
    "predicted.set_xlabel('Scores Full')\n",
    "predicted.set_ylabel('Reviews Full')\n",
    "#Subplot 3\n",
    "predicted_sharpen = plt.subplot(133)\n",
    "predicted_sharpen.hist(evaluated_reviews_full['PSS Score Sharpened'], bins=5, alpha=0.5, label='PSS Sharpen', color='#2300A8')\n",
    "predicted_sharpen.set_title('PSS Score Sharpened')\n",
    "predicted_sharpen.set_xlabel('Scores Full')\n",
    "predicted_sharpen.set_ylabel('Reviews Full')\n",
    "\n",
    "#Distributions for Medium dataset\n",
    "plots_size = (14,3)\n",
    "plt.figure(2, figsize=plots_size)\n",
    "#Subplot 1\n",
    "original = plt.subplot(131)\n",
    "original.hist(evaluated_reviews_medium['Original Rating'], bins=5, alpha=0.5, label='PSS')\n",
    "original.set_title('Original Rating')\n",
    "original.set_xlabel('Scores Medium')\n",
    "original.set_ylabel('Reviews Medium')\n",
    "#Subplot 2\n",
    "predicted = plt.subplot(132)\n",
    "predicted.hist(evaluated_reviews_medium['PSS Score'], bins=5, alpha=0.5, label='PSS', color='#00A658')\n",
    "predicted.set_title('PSS Score')\n",
    "predicted.set_xlabel('Scores Medium')\n",
    "predicted.set_ylabel('Reviews Medium')\n",
    "#Subplot 3\n",
    "predicted_sharpen = plt.subplot(133)\n",
    "predicted_sharpen.hist(evaluated_reviews_medium['PSS Score Sharpened'], bins=5, alpha=0.5, label='PSS Sharpen', color='#2300A8')\n",
    "predicted_sharpen.set_title('PSS Score Sharpened')\n",
    "predicted_sharpen.set_xlabel('Scores Medium')\n",
    "predicted_sharpen.set_ylabel('Reviews Medium')\n",
    "\n",
    "#Distributions for Small dataset\n",
    "plots_size = (14,3)\n",
    "plt.figure(3, figsize=plots_size)\n",
    "#Subplot 1\n",
    "original = plt.subplot(131)\n",
    "original.hist(evaluated_reviews_small['Original Rating'], bins=5, alpha=0.5, label='PSS')\n",
    "original.set_title('Original Rating')\n",
    "original.set_xlabel('Scores Small')\n",
    "original.set_ylabel('Reviews Small')\n",
    "#Subplot 2\n",
    "predicted = plt.subplot(132)\n",
    "predicted.hist(evaluated_reviews_small['PSS Score'], bins=5, alpha=0.5, label='PSS', color='#00A658')\n",
    "predicted.set_title('PSS Score')\n",
    "predicted.set_xlabel('Scores Small')\n",
    "predicted.set_ylabel('Reviews Small')\n",
    "#Subplot 3\n",
    "predicted_sharpen = plt.subplot(133)\n",
    "predicted_sharpen.hist(evaluated_reviews_small['PSS Score Sharpened'], bins=5, alpha=0.5, label='PSS Sharpen', color='#2300A8')\n",
    "predicted_sharpen.set_title('PSS Score Sharpened')\n",
    "predicted_sharpen.set_xlabel('Scores Small')\n",
    "predicted_sharpen.set_ylabel('Reviews Small')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
